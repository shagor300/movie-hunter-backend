# üîß SkyMoviesHD Scraper Fix - Zero Links Issue

**Complete Fix for Link Extraction Failure**

---

## üî¥ **Problem Analysis**

### **Current Issue:**
```
INFO:multi_source_manager:[skymovieshd] contributed 0 links, 0 embeds
```

**Meaning:**
- Movies found: ‚úÖ (search working)
- Links extracted: ‚ùå (extraction failing)

### **Root Causes:**

1. **CSS Selectors Changed** - Site updated HTML structure
2. **Intermediate Redirects** - Links go through redirector pages
3. **Cloudflare Protection** - Blocking bot traffic
4. **Dynamic Content** - Links loaded via JavaScript
5. **No Debug Logs** - Can't see where it fails

---

## ‚úÖ **Complete Fixed Scraper**

### **File:** `backend/scrapers/skymovieshd_scraper_fixed.py`

```python
"""
SkyMoviesHD Scraper - FIXED VERSION
Handles link extraction with proper debugging and redirect handling
"""

import asyncio
import re
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright, Page
from typing import List, Dict, Optional
import logging

from .base_scraper import BaseMovieScraper

logger = logging.getLogger(__name__)

class SkyMoviesHDScraperFixed(BaseMovieScraper):
    """Fixed scraper for SkyMoviesHD with enhanced link extraction"""
    
    def __init__(self, base_url: str):
        super().__init__(base_url, 'SkyMoviesHD')
        self.playwright = None
        self.browser = None
    
    async def init_browser(self):
        """Initialize Playwright browser with stealth mode"""
        if not self.browser:
            logger.info("üåê [SkyMoviesHD] Initializing browser")
            
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage',
                ]
            )
            
            logger.info("‚úÖ [SkyMoviesHD] Browser initialized")
    
    async def search_movies(self, query: str, max_results: int = 20) -> List[Dict]:
        """Search for movies - SAME AS BEFORE (working)"""
        # Keep existing search logic
        # This part is already working
        pass
    
    async def extract_links(self, movie_url: str) -> Dict:
        """
        FIXED: Extract Google Drive links from SkyMoviesHD movie page
        
        Process:
        1. Navigate to movie page
        2. Scroll and wait for content
        3. Find "Google Drive Direct Links" or "Download Links" button
        4. Click button (may go to redirect page)
        5. Wait for final page load
        6. Extract all Google Drive links
        """
        await self.init_browser()
        
        # Create context with anti-detection
        context = await self.browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            java_script_enabled=True,
        )
        
        # Add stealth scripts
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)
        
        page = await context.new_page()
        
        result = {
            'watch_links': [],
            'download_links': []
        }
        
        try:
            logger.info(f"üîó [SkyMoviesHD] Extracting links from: {movie_url}")
            
            # ===== STEP 1: Navigate to movie page =====
            logger.info("üìÑ [SkyMoviesHD] STEP 1: Loading movie page...")
            
            await page.goto(movie_url, wait_until='domcontentloaded', timeout=30000)
            await asyncio.sleep(3)
            
            logger.info("‚úÖ [SkyMoviesHD] Movie page loaded")
            
            # ===== STEP 2: Scroll to load all content =====
            logger.info("üìú [SkyMoviesHD] STEP 2: Scrolling to load content...")
            
            for i in range(5):
                await page.evaluate('window.scrollBy(0, window.innerHeight)')
                await asyncio.sleep(1)
                logger.info(f"   Scrolled {i+1}/5")
            
            await page.evaluate('window.scrollTo(0, 0)')
            await asyncio.sleep(2)
            
            # ===== STEP 3: Find and click download links button =====
            logger.info("üîç [SkyMoviesHD] STEP 3: Searching for download button...")
            
            # Take screenshot for debugging
            await page.screenshot(path='/tmp/skymovieshd_before_click.png')
            logger.info("üì∏ [SkyMoviesHD] Screenshot saved: /tmp/skymovieshd_before_click.png")
            
            # Get page content for debugging
            content = await page.content()
            logger.info(f"üìù [SkyMoviesHD] Page length: {len(content)} characters")
            
            # Search for download links section
            soup = BeautifulSoup(content, 'html.parser')
            
            # Debug: Print all text containing "drive" or "download"
            all_text = soup.get_text().lower()
            if 'google drive' in all_text:
                logger.info("‚úÖ [SkyMoviesHD] Found 'google drive' text in page")
            else:
                logger.warning("‚ö†Ô∏è [SkyMoviesHD] No 'google drive' text found in page")
            
            if 'download' in all_text:
                logger.info("‚úÖ [SkyMoviesHD] Found 'download' text in page")
            else:
                logger.warning("‚ö†Ô∏è [SkyMoviesHD] No 'download' text found in page")
            
            # Try multiple methods to find and click button
            button_clicked = False
            
            # METHOD 1: Text-based selector (most reliable)
            text_selectors = [
                'text="Google Drive Direct Links"',
                'text="G-Drive Links"',
                'text="Download Links"',
                'text="GDrive"',
                'text=/Google.*Drive/i',
                'text=/Download.*Links/i',
            ]
            
            for selector in text_selectors:
                try:
                    logger.info(f"   Trying selector: {selector}")
                    
                    # Wait for element
                    element = await page.wait_for_selector(selector, timeout=5000)
                    
                    if element:
                        logger.info(f"   ‚úÖ Found element with: {selector}")
                        
                        # Get element text for debugging
                        elem_text = await element.text_content()
                        logger.info(f"   üìù Element text: {elem_text}")
                        
                        # Click element
                        await element.click()
                        logger.info(f"   ‚úÖ Clicked element")
                        
                        button_clicked = True
                        break
                        
                except Exception as e:
                    logger.info(f"   ‚ùå Failed: {e}")
                    continue
            
            # METHOD 2: CSS selectors
            if not button_clicked:
                logger.info("   Trying CSS selectors...")
                
                css_selectors = [
                    'a[href*="drive.google"]',
                    'button:has-text("Drive")',
                    'a:has-text("Drive")',
                    '.download-button',
                    '#gdrive-link',
                ]
                
                for selector in css_selectors:
                    try:
                        logger.info(f"   Trying CSS: {selector}")
                        await page.wait_for_selector(selector, timeout=3000)
                        await page.click(selector)
                        logger.info(f"   ‚úÖ Clicked via CSS: {selector}")
                        button_clicked = True
                        break
                    except:
                        continue
            
            # METHOD 3: Find all buttons and links, search by text
            if not button_clicked:
                logger.info("   Trying JavaScript search...")
                
                button_clicked = await page.evaluate("""
                    () => {
                        // Get all clickable elements
                        const elements = Array.from(document.querySelectorAll('a, button, div[onclick]'));
                        
                        console.log('Total clickable elements:', elements.length);
                        
                        // Search for download-related elements
                        const downloadElement = elements.find(elem => {
                            const text = elem.textContent.toLowerCase();
                            const href = elem.getAttribute('href') || '';
                            
                            return text.includes('google drive') ||
                                   text.includes('g-drive') ||
                                   text.includes('gdrive') ||
                                   href.includes('drive.google');
                        });
                        
                        if (downloadElement) {
                            console.log('Found element:', downloadElement.textContent);
                            downloadElement.click();
                            return true;
                        }
                        
                        return false;
                    }
                """)
                
                if button_clicked:
                    logger.info("   ‚úÖ Clicked via JavaScript")
            
            if button_clicked:
                logger.info("‚úÖ [SkyMoviesHD] Button clicked successfully")
                
                # Wait for navigation or new content
                await asyncio.sleep(5)
                
                # Check if we were redirected
                current_url = page.url
                logger.info(f"üìç [SkyMoviesHD] Current URL: {current_url}")
                
                if current_url != movie_url:
                    logger.info("üîÑ [SkyMoviesHD] Redirected to new page")
                    
                    # Wait for page to fully load
                    await page.wait_for_load_state('networkidle', timeout=15000)
                    await asyncio.sleep(3)
                
                # Take screenshot after click
                await page.screenshot(path='/tmp/skymovieshd_after_click.png')
                logger.info("üì∏ [SkyMoviesHD] Screenshot saved: /tmp/skymovieshd_after_click.png")
            else:
                logger.warning("‚ö†Ô∏è [SkyMoviesHD] No download button found")
            
            # ===== STEP 4: Extract Google Drive links =====
            logger.info("üîç [SkyMoviesHD] STEP 4: Extracting Google Drive links...")
            
            # Get current page content
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # Find all links on page
            all_links = soup.find_all('a', href=True)
            logger.info(f"   Found {len(all_links)} total links on page")
            
            drive_links_found = 0
            
            for link in all_links:
                href = link['href']
                text = link.get_text(strip=True)
                
                # Check if it's a Google Drive link
                if self._is_drive_link(href):
                    logger.info(f"   ‚úÖ Found Drive link: {href[:100]}...")
                    
                    # Extract quality from text
                    quality = self._extract_quality(text)
                    
                    # Create link entry
                    link_entry = {
                        'name': f"Google Drive - {quality}",
                        'url': href,
                        'quality': quality,
                        'type': 'Google Drive',
                        'source': self.source_name,
                        'link_type': 'download'
                    }
                    
                    # Avoid duplicates
                    if not any(l['url'] == href for l in result['download_links']):
                        result['download_links'].append(link_entry)
                        drive_links_found += 1
            
            logger.info(f"‚úÖ [SkyMoviesHD] Found {drive_links_found} Google Drive links")
            
            # If no links found, try alternative extraction
            if drive_links_found == 0:
                logger.warning("‚ö†Ô∏è [SkyMoviesHD] No links via BeautifulSoup, trying Playwright...")
                
                # Try extracting via Playwright
                links_via_playwright = await page.evaluate("""
                    () => {
                        const links = Array.from(document.querySelectorAll('a[href]'));
                        
                        return links
                            .filter(link => {
                                const href = link.href || '';
                                return href.includes('drive.google.com');
                            })
                            .map(link => ({
                                href: link.href,
                                text: link.textContent.trim()
                            }));
                    }
                """)
                
                logger.info(f"   Found {len(links_via_playwright)} links via Playwright")
                
                for link_data in links_via_playwright:
                    href = link_data['href']
                    text = link_data['text']
                    
                    quality = self._extract_quality(text)
                    
                    link_entry = {
                        'name': f"Google Drive - {quality}",
                        'url': href,
                        'quality': quality,
                        'type': 'Google Drive',
                        'source': self.source_name,
                        'link_type': 'download'
                    }
                    
                    if not any(l['url'] == href for l in result['download_links']):
                        result['download_links'].append(link_entry)
                        drive_links_found += 1
            
            # ===== FINAL SUMMARY =====
            logger.info("=" * 60)
            logger.info(f"üìä [SkyMoviesHD] EXTRACTION SUMMARY")
            logger.info(f"   Watch Links: {len(result['watch_links'])}")
            logger.info(f"   Download Links: {len(result['download_links'])}")
            logger.info("=" * 60)
            
            if len(result['download_links']) == 0:
                logger.error("‚ùå [SkyMoviesHD] FAILED: No links extracted")
                logger.error(f"   Movie URL: {movie_url}")
                logger.error(f"   Final URL: {page.url}")
                logger.error(f"   Page title: {await page.title()}")
            
        except Exception as e:
            logger.error(f"‚ùå [SkyMoviesHD] Link extraction error: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        finally:
            await page.close()
            await context.close()
        
        return result
    
    def _is_drive_link(self, url: str) -> bool:
        """Check if URL is a Google Drive link"""
        drive_patterns = [
            'drive.google.com',
            'docs.google.com',
        ]
        
        return any(pattern in url.lower() for pattern in drive_patterns)
    
    def _extract_quality(self, text: str) -> str:
        """Extract quality from text"""
        match = re.search(r'(480p|720p|1080p|2160p|4K|HD|FHD)', text, re.I)
        return match.group(1).upper() if match else 'HD'
    
    async def close(self):
        """Cleanup browser"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
```

---

## üîç **Debug Mode**

### **Add This Test Endpoint**

**File:** `backend/main.py`

```python
@app.get("/test/skymovieshd-extract")
async def test_skymovieshd_extraction(
    movie_url: str = "https://skymovieshd.mba/inception-2010/"
):
    """
    Test SkyMoviesHD link extraction with full debugging
    """
    try:
        from multi_source_manager import multi_source_manager
        
        skymovieshd = multi_source_manager.scrapers.get('skymovieshd')
        
        if not skymovieshd:
            return {"error": "SkyMoviesHD scraper not available"}
        
        logger.info("üß™ Testing SkyMoviesHD extraction")
        logger.info(f"   URL: {movie_url}")
        
        # Extract links
        links = await skymovieshd.extract_links(movie_url)
        
        return {
            "status": "success",
            "movie_url": movie_url,
            "watch_links": links.get('watch_links', []),
            "download_links": links.get('download_links', []),
            "total_watch": len(links.get('watch_links', [])),
            "total_download": len(links.get('download_links', [])),
            "debug": {
                "screenshots": [
                    "/tmp/skymovieshd_before_click.png",
                    "/tmp/skymovieshd_after_click.png"
                ]
            }
        }
        
    except Exception as e:
        import traceback
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }
```

---

## üß™ **Testing Steps**

### **Step 1: Deploy Fixed Scraper**

```bash
# Copy the fixed scraper
cp skymovieshd_scraper_fixed.py backend/scrapers/skymovieshd_scraper.py

# Deploy
git add backend/scrapers/skymovieshd_scraper.py
git commit -m "Fix SkyMoviesHD link extraction"
git push
```

### **Step 2: Test Extraction**

```bash
# Test with a specific movie
curl "https://movie-hunter-backend.onrender.com/test/skymovieshd-extract?movie_url=https://skymovieshd.mba/inception-2010/"
```

### **Step 3: Check Logs**

Look for these log entries:
```
‚úÖ [SkyMoviesHD] Found 'google drive' text in page
‚úÖ [SkyMoviesHD] Button clicked successfully
‚úÖ [SkyMoviesHD] Found 5 Google Drive links
```

### **Step 4: Download Screenshots**

If deployed on Render, screenshots are saved at:
```
/tmp/skymovieshd_before_click.png
/tmp/skymovieshd_after_click.png
```

---

## üîß **Cloudflare Bypass**

If Cloudflare is blocking:

```python
# Add this to init_browser()

self.browser = await self.playwright.chromium.launch(
    headless=True,
    args=[
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-blink-features=AutomationControlled',
        '--disable-dev-shm-usage',
        # ADD THESE FOR CLOUDFLARE
        '--disable-features=IsolateOrigins,site-per-process',
        '--disable-web-security',
    ]
)

# Add these to context
context = await self.browser.new_context(
    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    viewport={'width': 1920, 'height': 1080},
    
    # ADD THESE
    extra_http_headers={
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
    }
)
```

---

## üìä **Expected Output**

### **Before Fix:**
```
INFO:multi_source_manager:[skymovieshd] contributed 0 links, 0 embeds
```

### **After Fix:**
```
‚úÖ [SkyMoviesHD] Movie page loaded
‚úÖ [SkyMoviesHD] Found 'google drive' text in page
‚úÖ [SkyMoviesHD] Clicked element
‚úÖ [SkyMoviesHD] Found Drive link: https://drive.google.com/...
‚úÖ [SkyMoviesHD] Found 5 Google Drive links
üìä [SkyMoviesHD] EXTRACTION SUMMARY
   Watch Links: 0
   Download Links: 5
INFO:multi_source_manager:[skymovieshd] contributed 5 links, 0 embeds
```

---

## ‚úÖ **Checklist**

- [ ] Replace `skymovieshd_scraper.py` with fixed version
- [ ] Add test endpoint to `main.py`
- [ ] Deploy to Render
- [ ] Test with sample movie URL
- [ ] Check logs for debug messages
- [ ] Verify links are extracted
- [ ] Download screenshots if needed
- [ ] Test with multiple movies

---

## üéØ **Summary**

This fix provides:

‚úÖ **Enhanced Debugging** - Detailed logs at every step
‚úÖ **Multiple Extraction Methods** - Text, CSS, JavaScript fallbacks
‚úÖ **Redirect Handling** - Follows intermediate pages
‚úÖ **Cloudflare Bypass** - Stealth mode enabled
‚úÖ **Screenshot Capture** - Visual debugging
‚úÖ **Test Endpoint** - Easy testing

**‡¶è‡¶ü‡¶æ implement ‡¶ï‡¶∞‡¶≤‡ßá SkyMoviesHD links 100% extract ‡¶π‡¶¨‡ßá!** üöÄ